{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-21T00:43:32.259263Z",
     "start_time": "2023-04-21T00:43:20.367187Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\russi\\venv\\Lib\\site-packages\\tensorflow_addons\\utils\\tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm.keras import TqdmCallback\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-21T00:32:34.625136Z",
     "start_time": "2023-04-21T00:32:33.945049Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"Выборка для обучения получена из работы\n",
    "Arrhenius Crossover Temperature of Glass-Forming Liquids Predicted by an Artificial Neural Network \"\"\"\n",
    "# Подготовленные данные в виде Excel таблицы, в случае отсутсвия можете получить по ссылке\n",
    "# https://disk.yandex.ru/i/JURRL-BjFInPUg\n",
    "# Дополнительная информация:\n",
    "# В таблице 91 запись, из них 57 - с известными экспериментальными T_A_empirical, остальные без (NaN)\n",
    "# Обязательные столбцы при составлении выборки: ['T_g','T_m','T_A_empirical','m']\n",
    "try:\n",
    "    excel_import = pd.read_excel('..\\\\data\\\\input_data.xlsx')\n",
    "except FileNotFoundError:\n",
    "    print(f'В папку с NoteBook\\'ом добавьте файл input_data.xlsx.\\n'\n",
    "          f'Скачать можно по ссылке https://disk.yandex.ru/i/JURRL-BjFInPUg')\n",
    "    raise FileNotFoundError\n",
    "excel_import.loc[:, 'T_g/T_m'] = excel_import.loc[:, 'T_g'] / excel_import.loc[:, 'T_m']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-21T00:32:36.036566Z",
     "start_time": "2023-04-21T00:32:36.016566Z"
    }
   },
   "outputs": [],
   "source": [
    "# Конфигурация нейронки\n",
    "BATCH_SIZE = 128  # размер пакета 128>57, SGD переходит в обычный градиентный спуск\n",
    "TRAIN_RATE = 0.3\n",
    "EPOCHS = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-21T00:32:37.065939Z",
     "start_time": "2023-04-21T00:32:37.050930Z"
    }
   },
   "outputs": [],
   "source": [
    "## После нахождения оптимального ввода поищем оптимальное число нейронов\n",
    "def get_model(neuron_count=10):\n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.InputLayer(input_shape=(2,)),\n",
    "        tf.keras.layers.Dense(neuron_count, activation='tanh'),\n",
    "        tf.keras.layers.Dense(neuron_count, activation='tanh'),\n",
    "        tf.keras.layers.Dense(1),\n",
    "    ])\n",
    "    optimizer = tf.keras.optimizers.SGD(learning_rate=TRAIN_RATE)\n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss='mse')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-21T00:32:40.049076Z",
     "start_time": "2023-04-21T00:32:39.384095Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T_g</th>\n",
       "      <th>T_m</th>\n",
       "      <th>T_g/T_m</th>\n",
       "      <th>m</th>\n",
       "      <th>T_A_empirical</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>995</td>\n",
       "      <td>1664</td>\n",
       "      <td>0.597957</td>\n",
       "      <td>59.0</td>\n",
       "      <td>1839.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>1087</td>\n",
       "      <td>1393</td>\n",
       "      <td>0.780330</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1503.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>1113</td>\n",
       "      <td>1825</td>\n",
       "      <td>0.609863</td>\n",
       "      <td>54.0</td>\n",
       "      <td>2010.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>530</td>\n",
       "      <td>723</td>\n",
       "      <td>0.733057</td>\n",
       "      <td>36.0</td>\n",
       "      <td>1073.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>208</td>\n",
       "      <td>321</td>\n",
       "      <td>0.647975</td>\n",
       "      <td>125.0</td>\n",
       "      <td>328.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>179</td>\n",
       "      <td>238</td>\n",
       "      <td>0.752101</td>\n",
       "      <td>75.0</td>\n",
       "      <td>241.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>185</td>\n",
       "      <td>270</td>\n",
       "      <td>0.685185</td>\n",
       "      <td>70.0</td>\n",
       "      <td>262.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>195</td>\n",
       "      <td>275</td>\n",
       "      <td>0.709091</td>\n",
       "      <td>70.0</td>\n",
       "      <td>261.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>187</td>\n",
       "      <td>223</td>\n",
       "      <td>0.838565</td>\n",
       "      <td>60.0</td>\n",
       "      <td>251.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>196</td>\n",
       "      <td>234</td>\n",
       "      <td>0.837607</td>\n",
       "      <td>66.0</td>\n",
       "      <td>268.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>255</td>\n",
       "      <td>325</td>\n",
       "      <td>0.784615</td>\n",
       "      <td>96.0</td>\n",
       "      <td>309.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>191</td>\n",
       "      <td>293</td>\n",
       "      <td>0.651877</td>\n",
       "      <td>53.0</td>\n",
       "      <td>338.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>318</td>\n",
       "      <td>387</td>\n",
       "      <td>0.821705</td>\n",
       "      <td>73.0</td>\n",
       "      <td>461.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>208</td>\n",
       "      <td>299</td>\n",
       "      <td>0.695652</td>\n",
       "      <td>76.0</td>\n",
       "      <td>270.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>243</td>\n",
       "      <td>329</td>\n",
       "      <td>0.738602</td>\n",
       "      <td>81.0</td>\n",
       "      <td>341.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>237</td>\n",
       "      <td>242</td>\n",
       "      <td>0.979339</td>\n",
       "      <td>72.0</td>\n",
       "      <td>314.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>294</td>\n",
       "      <td>373</td>\n",
       "      <td>0.788204</td>\n",
       "      <td>85.0</td>\n",
       "      <td>397.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>164</td>\n",
       "      <td>214</td>\n",
       "      <td>0.766355</td>\n",
       "      <td>52.0</td>\n",
       "      <td>321.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>221</td>\n",
       "      <td>315</td>\n",
       "      <td>0.701587</td>\n",
       "      <td>73.0</td>\n",
       "      <td>309.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>340</td>\n",
       "      <td>373</td>\n",
       "      <td>0.911528</td>\n",
       "      <td>94.0</td>\n",
       "      <td>421.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>209</td>\n",
       "      <td>240</td>\n",
       "      <td>0.870833</td>\n",
       "      <td>76.0</td>\n",
       "      <td>280.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>192</td>\n",
       "      <td>232</td>\n",
       "      <td>0.827586</td>\n",
       "      <td>72.0</td>\n",
       "      <td>251.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>204</td>\n",
       "      <td>296</td>\n",
       "      <td>0.689189</td>\n",
       "      <td>69.0</td>\n",
       "      <td>286.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>250</td>\n",
       "      <td>367</td>\n",
       "      <td>0.681199</td>\n",
       "      <td>87.0</td>\n",
       "      <td>311.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>133</td>\n",
       "      <td>203</td>\n",
       "      <td>0.655172</td>\n",
       "      <td>72.0</td>\n",
       "      <td>250.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>189</td>\n",
       "      <td>250</td>\n",
       "      <td>0.756000</td>\n",
       "      <td>98.0</td>\n",
       "      <td>279.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>160</td>\n",
       "      <td>224</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>99.0</td>\n",
       "      <td>290.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>122</td>\n",
       "      <td>174</td>\n",
       "      <td>0.701149</td>\n",
       "      <td>55.0</td>\n",
       "      <td>240.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>173</td>\n",
       "      <td>271</td>\n",
       "      <td>0.638376</td>\n",
       "      <td>70.0</td>\n",
       "      <td>312.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>176</td>\n",
       "      <td>353</td>\n",
       "      <td>0.498584</td>\n",
       "      <td>75.0</td>\n",
       "      <td>314.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>245</td>\n",
       "      <td>342</td>\n",
       "      <td>0.716374</td>\n",
       "      <td>96.0</td>\n",
       "      <td>330.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>340</td>\n",
       "      <td>373</td>\n",
       "      <td>0.911528</td>\n",
       "      <td>94.0</td>\n",
       "      <td>421.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>380</td>\n",
       "      <td>473</td>\n",
       "      <td>0.803383</td>\n",
       "      <td>54.0</td>\n",
       "      <td>498.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>286</td>\n",
       "      <td>418</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>70.0</td>\n",
       "      <td>433.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>800</td>\n",
       "      <td>1230</td>\n",
       "      <td>0.650407</td>\n",
       "      <td>36.0</td>\n",
       "      <td>1368.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>647</td>\n",
       "      <td>1126</td>\n",
       "      <td>0.574600</td>\n",
       "      <td>41.0</td>\n",
       "      <td>1214.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>677</td>\n",
       "      <td>1152</td>\n",
       "      <td>0.587674</td>\n",
       "      <td>48.0</td>\n",
       "      <td>1287.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>701</td>\n",
       "      <td>1173</td>\n",
       "      <td>0.597613</td>\n",
       "      <td>71.0</td>\n",
       "      <td>1280.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>651</td>\n",
       "      <td>1226</td>\n",
       "      <td>0.530995</td>\n",
       "      <td>60.0</td>\n",
       "      <td>1390.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>675</td>\n",
       "      <td>1123</td>\n",
       "      <td>0.601069</td>\n",
       "      <td>49.0</td>\n",
       "      <td>1324.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>729</td>\n",
       "      <td>1503</td>\n",
       "      <td>0.485030</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1557.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>675</td>\n",
       "      <td>1220</td>\n",
       "      <td>0.553279</td>\n",
       "      <td>46.0</td>\n",
       "      <td>1384.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>722</td>\n",
       "      <td>1450</td>\n",
       "      <td>0.497931</td>\n",
       "      <td>33.0</td>\n",
       "      <td>1738.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>672</td>\n",
       "      <td>1125</td>\n",
       "      <td>0.597333</td>\n",
       "      <td>45.0</td>\n",
       "      <td>1242.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>715</td>\n",
       "      <td>1364</td>\n",
       "      <td>0.524194</td>\n",
       "      <td>45.0</td>\n",
       "      <td>1549.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>640</td>\n",
       "      <td>1173</td>\n",
       "      <td>0.545610</td>\n",
       "      <td>45.0</td>\n",
       "      <td>1300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>617</td>\n",
       "      <td>1026</td>\n",
       "      <td>0.601365</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1144.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>625</td>\n",
       "      <td>1050</td>\n",
       "      <td>0.595238</td>\n",
       "      <td>44.0</td>\n",
       "      <td>1205.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>600</td>\n",
       "      <td>1283</td>\n",
       "      <td>0.467654</td>\n",
       "      <td>95.0</td>\n",
       "      <td>1400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>669</td>\n",
       "      <td>1185</td>\n",
       "      <td>0.564557</td>\n",
       "      <td>64.0</td>\n",
       "      <td>1313.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>687</td>\n",
       "      <td>1279</td>\n",
       "      <td>0.537138</td>\n",
       "      <td>41.0</td>\n",
       "      <td>1472.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>632</td>\n",
       "      <td>1058</td>\n",
       "      <td>0.597353</td>\n",
       "      <td>64.0</td>\n",
       "      <td>1160.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>560</td>\n",
       "      <td>1030</td>\n",
       "      <td>0.543689</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1157.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>648</td>\n",
       "      <td>1071</td>\n",
       "      <td>0.605042</td>\n",
       "      <td>106.0</td>\n",
       "      <td>1186.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>760</td>\n",
       "      <td>1283</td>\n",
       "      <td>0.592362</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1506.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>930</td>\n",
       "      <td>1448</td>\n",
       "      <td>0.642265</td>\n",
       "      <td>136.0</td>\n",
       "      <td>1658.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>890</td>\n",
       "      <td>1363</td>\n",
       "      <td>0.652971</td>\n",
       "      <td>60.0</td>\n",
       "      <td>1545.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     T_g   T_m   T_g/T_m      m  T_A_empirical\n",
       "34   995  1664  0.597957   59.0         1839.0\n",
       "35  1087  1393  0.780330   24.0         1503.0\n",
       "36  1113  1825  0.609863   54.0         2010.0\n",
       "37   530   723  0.733057   36.0         1073.0\n",
       "38   208   321  0.647975  125.0          328.0\n",
       "39   179   238  0.752101   75.0          241.0\n",
       "40   185   270  0.685185   70.0          262.0\n",
       "41   195   275  0.709091   70.0          261.0\n",
       "42   187   223  0.838565   60.0          251.0\n",
       "43   196   234  0.837607   66.0          268.0\n",
       "44   255   325  0.784615   96.0          309.0\n",
       "45   191   293  0.651877   53.0          338.0\n",
       "46   318   387  0.821705   73.0          461.0\n",
       "47   208   299  0.695652   76.0          270.0\n",
       "48   243   329  0.738602   81.0          341.0\n",
       "49   237   242  0.979339   72.0          314.0\n",
       "50   294   373  0.788204   85.0          397.0\n",
       "51   164   214  0.766355   52.0          321.0\n",
       "52   221   315  0.701587   73.0          309.0\n",
       "53   340   373  0.911528   94.0          421.0\n",
       "54   209   240  0.870833   76.0          280.0\n",
       "55   192   232  0.827586   72.0          251.0\n",
       "56   204   296  0.689189   69.0          286.0\n",
       "57   250   367  0.681199   87.0          311.0\n",
       "58   133   203  0.655172   72.0          250.0\n",
       "59   189   250  0.756000   98.0          279.0\n",
       "60   160   224  0.714286   99.0          290.0\n",
       "61   122   174  0.701149   55.0          240.0\n",
       "62   173   271  0.638376   70.0          312.0\n",
       "63   176   353  0.498584   75.0          314.0\n",
       "64   245   342  0.716374   96.0          330.0\n",
       "65   340   373  0.911528   94.0          421.0\n",
       "66   380   473  0.803383   54.0          498.0\n",
       "67   286   418  0.684211   70.0          433.0\n",
       "68   800  1230  0.650407   36.0         1368.0\n",
       "69   647  1126  0.574600   41.0         1214.0\n",
       "70   677  1152  0.587674   48.0         1287.0\n",
       "71   701  1173  0.597613   71.0         1280.0\n",
       "72   651  1226  0.530995   60.0         1390.0\n",
       "73   675  1123  0.601069   49.0         1324.0\n",
       "74   729  1503  0.485030   40.0         1557.0\n",
       "75   675  1220  0.553279   46.0         1384.0\n",
       "76   722  1450  0.497931   33.0         1738.0\n",
       "77   672  1125  0.597333   45.0         1242.0\n",
       "78   715  1364  0.524194   45.0         1549.0\n",
       "79   640  1173  0.545610   45.0         1300.0\n",
       "80   617  1026  0.601365   50.0         1144.0\n",
       "81   625  1050  0.595238   44.0         1205.0\n",
       "82   600  1283  0.467654   95.0         1400.0\n",
       "83   669  1185  0.564557   64.0         1313.0\n",
       "84   687  1279  0.537138   41.0         1472.0\n",
       "85   632  1058  0.597353   64.0         1160.0\n",
       "86   560  1030  0.543689   50.0         1157.0\n",
       "87   648  1071  0.605042  106.0         1186.0\n",
       "88   760  1283  0.592362   24.0         1506.0\n",
       "89   930  1448  0.642265  136.0         1658.0\n",
       "90   890  1363  0.652971   60.0         1545.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = excel_import[excel_import.T_A_empirical.notna()].loc[:,\n",
    "             ['T_g', 'T_m', 'T_g/T_m', 'm', 'T_A_empirical']]\n",
    "## Данные, которые с известным экспериментальным значением, поделим на 10000, чтобы значения были в [0,1]\n",
    "\n",
    "target_normalizer = tf.keras.layers.Normalization(axis=1)\n",
    "target_normalizer.adapt(train_data['T_A_empirical'])\n",
    "\n",
    "target_denormalizer = tf.keras.layers.Normalization(axis=1, invert=True)\n",
    "target_denormalizer.adapt(train_data['T_A_empirical'])\n",
    "\n",
    "train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "train_target = tf.transpose(target_normalizer(train_data['T_A_empirical']))\n",
    "input_normalizer = tf.keras.layers.Normalization()\n",
    "input_normalizer.adapt(train_data[['T_g','T_m']])\n",
    "train_input = input_normalizer(train_data[['T_g','T_m']])\n",
    "\n",
    "tqdm_callback = tfa.callbacks.TQDMProgressBar()\n",
    "to_do = True\n",
    "if to_do:\n",
    "    for neuron_count in range(2,15):\n",
    "        model = get_model(neuron_count)\n",
    "        model.fit(train_input, train_target,\n",
    "                  verbose=0,  # отключение вывода tf\n",
    "                  callbacks=[TqdmCallback(verbose=0)],\n",
    "                  batch_size=BATCH_SIZE,\n",
    "                  epochs=EPOCHS)  # вывод с помощью TQDM\n",
    "        model.save(f'models\\\\series_neuron\\\\model_{neuron_count}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
